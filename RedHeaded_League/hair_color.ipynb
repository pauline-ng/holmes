{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os, io\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "#from skimage import io\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2hsv\n",
    "import matplotlib.pyplot as plt \n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "\n",
    "folders = [\"pics/blonde/blonde*jpg\", \"pics/brunette/brown*jpg\", \"pics/redheads/red*jpg\"]\n",
    "X =[]\n",
    "Y = []\n",
    "imgs_with_channel = []\n",
    "\n",
    "# needed to download pics for this example\n",
    "def download_files (repository, directory_to_download):\n",
    "\n",
    "   \n",
    "    \n",
    "    # go to github repository\n",
    "    http_response = urlopen(repository)\n",
    "    zipfile = ZipFile(io.BytesIO(http_response.read()))\n",
    "    files = zipfile.namelist()\n",
    "    for file in files:\n",
    "        if directory_to_download in file:\n",
    "            outfile = file[file.find (directory_to_download):]\n",
    "            outdir = os.path.dirname (outfile)\n",
    "            if not os.path.exists (outdir):\n",
    "                os.makedirs (outdir, exist_ok=True)\n",
    "            if not file.endswith (\"/\"):\n",
    "              #  print (file)\n",
    "              #  print (outfile)\n",
    "                zipfile.extract (file, \".\")\n",
    "                shutil.copy (file, outfile)\n",
    "            \n",
    "    \n",
    "repository = \"https://github.com/pauline-ng/holmes/archive/refs/heads/master.zip\"\n",
    "directory_to_download = \"pics/\"\n",
    "\n",
    "download_files(repository, directory_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "def resize_images ():\n",
    "    jpg_files=glob.glob (folders[0])\n",
    "    for jpg_file in jpg_files:\n",
    "        min_width = 1000\n",
    "        min_height = 1000\n",
    "\n",
    "        im = Image.open(jpg_file) # Can be many different formats.\n",
    "        pix = im.load()\n",
    "        print (im.size)  # Get the width and hight of the image for iterating over\n",
    "        if im.size[0] < min_width:\n",
    "            min_width = im.size[0]\n",
    "        if im.size[1] < min_height:\n",
    "            min_height = im.size[1]\n",
    "\n",
    "        \n",
    "print (\"hello\")\n",
    "\n",
    "# assign jpg_files all of the hair-colored jpgs\n",
    "jpg_files = []\n",
    "for folder in folders:\n",
    "    jpg_files.extend (glob.glob (folder))\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE = 50\n",
    "\n",
    "for jpg_file in jpg_files:\n",
    "    label = os.path.basename (jpg_file).replace (\".jpg\", \"\")\n",
    "    label = ''.join([i for i in label if not i.isdigit()]) \n",
    "\n",
    "    im = Image.open(jpg_file) # Can be many different formats.\n",
    "\n",
    "    x=20\n",
    "    y=20\n",
    "    IMG_PX_SIZE = 20 # pixels\n",
    "    rgb_img = skimage.io.imread (jpg_file)\n",
    "    \n",
    "    # resize images to all the same size\n",
    "    #rgb_img_resize = rgb_img.resize(IMG_SIZE, IMG_SIZE, 0)\n",
    "    #rgb_img = rgb_img.resize (20,20,0)\n",
    "    rgb_img = resize (rgb_img, (IMG_PX_SIZE,IMG_PX_SIZE))\n",
    "    # get HSV representation of image\n",
    " #   hsv_img = rgb2hsv (rgb_img)\n",
    "    \n",
    "    # get Hue values of image (igeore saturation and value)\n",
    "    # do over, need to resize\n",
    "  #  hue_img = hsv_img[0:x, 0:y, 0]\n",
    "    #hue_img_resize = cv2\n",
    " #   print (hue_img.shape)\n",
    "    \n",
    "    #print (pix[x,y])  # Get the RGBA Value of the a pixel of an image\n",
    "  #  print (hue_img[x,y])\n",
    "   # print (rgb_img.reshape (1, IMG_PX_SIZE*IMG_PX_SIZE*3)[0])  # flatten into an array\n",
    " #   X.append (hue_img.reshape ((hue_img.shape[0], x*y*3)))\n",
    "    #X.append (np.array(hue_img))    \n",
    "    X.append (rgb_img.reshape (1, x*y*3)[0]) # flatten into a 1-D array\n",
    "    Y.append (label)\n",
    "    \n",
    "\n",
    " #   img_with_channel = np.expand_dims (hue_img, axis=-1)\n",
    "  #  imgs_with_channel.append (img_with_channel)\n",
    "#        print (depth_with_channel.shape)\n",
    "\n",
    "\n",
    "    # final step-forming the training data list with numpy array of the images \n",
    "   # training_data.append([np.array(hue_img), np.array(label)]) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_SIZE = 50\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "#from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_groups = 3  # blonde, red, brunette\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=num_groups)\n",
    "\n",
    "model.fit (X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = model.predict (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blonde' 'blonde' 'blonde' 'blonde' 'blonde' 'red' 'blonde' 'blonde'\n",
      " 'red' 'blonde' 'brown' 'brown' 'brown' 'brown' 'brown' 'brown' 'brown'\n",
      " 'brown' 'brown' 'brown' 'red' 'red' 'red' 'red' 'red' 'red' 'red' 'red'\n",
      " 'red' 'red' 'red' 'red' 'red']\n"
     ]
    }
   ],
   "source": [
    "print (model.predict (X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pics/blonde/blonde4.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde10.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde2.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde5.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde6.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde9.jpg\n",
      "[0.33333333 0.         0.66666667]\n",
      "pics/blonde/blonde1.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde8.jpg\n",
      "[1. 0. 0.]\n",
      "pics/blonde/blonde7.jpg\n",
      "[0.33333333 0.         0.66666667]\n",
      "pics/blonde/blonde3.jpg\n",
      "[1. 0. 0.]\n",
      "pics/brunette/brown7.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown2.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown3.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown9.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown5.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown6.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown4.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown1.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown10.jpg\n",
      "[0. 1. 0.]\n",
      "pics/brunette/brown8.jpg\n",
      "[0. 1. 0.]\n",
      "pics/redheads/red10.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red9.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red5.jpg\n",
      "[0.         0.33333333 0.66666667]\n",
      "pics/redheads/red7.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red6.jpg\n",
      "[0.         0.33333333 0.66666667]\n",
      "pics/redheads/red11.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red1.jpg\n",
      "[0.33333333 0.         0.66666667]\n",
      "pics/redheads/red3.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red4.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red2.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red8.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red13.jpg\n",
      "[0. 0. 1.]\n",
      "pics/redheads/red12.jpg\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#print \"generated examples to predict:\\n\",predict,\"\\n\"\n",
    "# predict class probabilities for each class for each value and convert to DataFrame\n",
    "probs = model.predict_proba(X)\n",
    "#print (\"all probabilities:\\n\", probs, \"\\n\")\n",
    "for index, prob in enumerate (probs):\n",
    "    jpg_file = jpg_files[index]\n",
    "    print (jpg_file)\n",
    "    print (str(prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "red1 has a component of blonde in it, not truly red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cf49b518e874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/65269382/how-can-i-visualize-the-test-samples-of-k-nearest-neighbour-classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Adding axes annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "\n",
    "# visualization\n",
    "# https://stackoverflow.com/questions/65269382/how-can-i-visualize-the-test-samples-of-k-nearest-neighbour-classifier\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "plot_decision_regions(X, Y, clf=model, legend=2)# Adding axes annotations\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Knn with K=3\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def get_neighbors(xs, sample):\n",
    "    neighbors = [(x, np.sum(np.abs(x - sample))) for x in xs]\n",
    "    neighbors = sorted(neighbors, key=lambda x: x[1])\n",
    "    return np.array([x for x, _ in neighbors])\n",
    "\n",
    "colors_array = []\n",
    "for hair_color in Y:\n",
    "    color = hair_color\n",
    "    if hair_color == \"blonde\":\n",
    "        color = \"yellow\"\n",
    "    colors_array.append (color)\n",
    "    \n",
    "_, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "for i in range(4):\n",
    "    sample = X[i]\n",
    "    neighbors = get_neighbors(X, sample)\n",
    " #   print (X)\n",
    "#    print (X[:,0])\n",
    " #   ax[i].scatter(X[:, 0], X[:, 1], c=\"skyblue\")\n",
    "    ax[i].scatter(neighbors[:, 0], neighbors[:, 1], c=colors_array) #edgecolor=\"green\")\n",
    "    ax[i].scatter(sample[0], sample[1], marker=\"+\", c=\"red\", s=100)\n",
    "    ax[i].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
